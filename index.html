<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting">
  <meta property="og:title" content="NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting"/>
  <meta property="og:description" content="An innovative approach to volume visualization through natural language interaction via LLM multi-agents and editable 3D Gaussian Splatting, enabling intuitive exploration of 3D datasets."/>
  <meta property="og:url" content="https://nli4volvis.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/teaser.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting">
  <meta name="twitter:description" content="An innovative approach to volume visualization through natural language interaction via LLM multi-agents and editable 3D Gaussian Splatting, enabling intuitive exploration of 3D datasets.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/teaser.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="volume visualization, large language model, LLM, multi-agents, language interface, NLI, scientific visualization, 3D Gaussian Splatting, human-computer interaction">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico?v=2">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<!-- Home icon -->
<div style="position: fixed; top: 20px; left: 20px; z-index: 1000;">
  <a href="https://kuangshiai.github.io" target="_blank" 
     style="display: inline-block; padding: 10px; background-color: rgba(0,0,0,0.7); border-radius: 50%; 
            color: white; text-decoration: none; box-shadow: 0 2px 10px rgba(0,0,0,0.3); 
            transition: all 0.3s ease;" 
     onmouseover="this.style.backgroundColor='rgba(0,0,0,0.9)'; this.style.transform='scale(1.1)'" 
     onmouseout="this.style.backgroundColor='rgba(0,0,0,0.7)'; this.style.transform='scale(1)'">
    <i class="fas fa-home" style="font-size: 18px;"></i>
  </a>
</div>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://kuangshiai.github.io/" target="_blank">Kuangshi Ai</a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=M8M1ZwkAAAAJ&hl=en" target="_blank">Kaiyuan Tang</a>,</span>
                  <span class="author-block">
                    <a href="https://sites.nd.edu/chaoli-wang/" target="_blank">Chaoli Wang</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Notre Dame<br>IEEE Transactions on Visualization and Computer Graphics (TVCG) 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="#" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/KuangshiAi/nli4volvis" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="#" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.jpg" alt="Teaser Image" style="width: 100%; height: auto; max-width: 1600px; display: block; margin: 0 auto;"/>
      <h2 class="subtitle has-text-centered">
        NLI4VolVis revolutionizes volume data exploration by enabling users to interact with complex 3D datasets through natural language commands via LLM multi-agents and editable 3D Gaussian Splatting, making scientific visualization more accessible and intuitive.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Traditional volume visualization (VolVis) methods, like direct volume rendering, suffer from rigid transfer function designs and high computational costs. Although novel view synthesis approaches enhance rendering efficiency, they require additional learning effort for non-experts and lack support for semantic-level interaction. To bridge this gap, we propose NLI4VolVis, an interactive system that enables users to explore, query, and edit volumetric scenes using natural language.
          </p>
          <p>
            NLI4VolVis integrates multi-view semantic segmentation and vision-language models to extract and understand semantic components in a scene. We introduce a multi-agent large language model architecture equipped with extensive function-calling tools to interpret user intents and execute visualization tasks. The agents leverage external tools and declarative VolVis commands to interact with the VolVis engine powered by 3D editable Gaussians, enabling open-vocabulary object querying, real-time scene editing, best-view selection, and 2D stylization.
          </p>
          <p>
            We validate our system through case studies and a user study, highlighting its improved accessibility and usability in volumetric data exploration.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Case Studies section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">Case Studies</h2>
          <div class="content has-text-justified">
            <p>
              We demonstrate NLI4VolVis capabilities through six representative case studies, showcasing the system's ability to handle diverse datasets and natural language interactions across different visualization scenarios.
            </p>
          </div>
          
          <!-- Case studies grid -->
          <div class="columns is-multiline" style="margin-top: 2rem;">
            <!-- Carp Case Study -->
            <div class="column is-half">
              <div class="box" style="height: 100%;">
                <h4 class="title is-5 has-text-centered">Carp</h4>
                <div class="has-text-centered" style="margin-bottom: 1rem;">
                  <video controls style="width: 100%; max-width: 400px; height: auto; border-radius: 8px;">
                    <source src="static/videos/carp.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="content has-text-justified">
                  <p>
                    Biological dataset segmented into seven components with guided tours and structure highlighting. Users can isolate fins, enhance specific parts like the pectoral fin, and apply stylized transformations such as "Transform the entire fish into a cyborg" in real time.
                  </p>
                </div>
              </div>
            </div>
            
            <!-- Backpack Case Study -->
            <div class="column is-half">
              <div class="box" style="height: 100%;">
                <h4 class="title is-5 has-text-centered">Backpack</h4>
                <div class="has-text-centered" style="margin-bottom: 1rem;">
                  <video controls style="width: 100%; max-width: 400px; height: auto; border-radius: 8px;">
                    <source src="static/videos/backpack.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="content has-text-justified">
                  <p>
                    CT scan exploration using vague but natural descriptions like “the box,” “the storage container,” or “the square-shaped object.” The system handles open-ended references through vision-language embeddings, identifying and highlighting correct components.
                  </p>
                </div>
              </div>
            </div>
            
            <!-- Chameleon Case Study -->
            <div class="column is-half">
              <div class="box" style="height: 100%;">
                <h4 class="title is-5 has-text-centered">Chameleon</h4>
                <div class="has-text-centered" style="margin-bottom: 1rem;">
                  <video controls style="width: 100%; max-width: 400px; height: auto; border-radius: 8px;">
                    <source src="static/videos/chameleon.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="content has-text-justified">
                  <p>
                    Context-driven visualization demonstrating adaptive lighting and environmental styling. When asked "How might the chameleon look in a desert?" the system changes skin color to match desert environments and stylizes the scene accordingly through iterative perception and reasoning.
                  </p>
                </div>
              </div>
            </div>
            
            <!-- Kingsnake Case Study -->
            <div class="column is-half">
              <div class="box" style="height: 100%;">
                <h4 class="title is-5 has-text-centered">Kingsnake</h4>
                <div class="has-text-centered" style="margin-bottom: 1rem;">
                  <video controls style="width: 100%; max-width: 400px; height: auto; border-radius: 8px;">
                    <source src="static/videos/kingsnake.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="content has-text-justified">
                  <p>
                    Implicit instruction interpretation where "Display the snake inside the egg" leads the system to render a fully visible snake within a semi-transparent egg, demonstrating natural language understanding and automatic opacity adjustment.
                  </p>
                </div>
              </div>
            </div>
            
            <!-- Mantle Temperature Case Study -->
            <div class="column is-half">
              <div class="box" style="height: 100%;">
                <h4 class="title is-5 has-text-centered">Mantle Temperature</h4>
                <div class="has-text-centered" style="margin-bottom: 1rem;">
                  <video controls style="width: 100%; max-width: 400px; height: auto; border-radius: 8px;">
                    <source src="static/videos/mantle.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="content has-text-justified">
                  <p>
                    Temperature simulation with colormap visualization from green (coolest) to orange (hottest). Users can highlight specific temperature regions like "hot mantle in bright blue" and apply creative stylizations such as transforming the scene to resemble a Black Forest cake, showcasing scientific precision with artistic creativity.
                  </p>
                </div>
              </div>
            </div>
            
            <!-- Supernova Case Study -->
            <div class="column is-half">
              <div class="box" style="height: 100%;">
                <h4 class="title is-5 has-text-centered">Supernova</h4>
                <div class="has-text-centered" style="margin-bottom: 1rem;">
                  <video controls style="width: 100%; max-width: 400px; height: auto; border-radius: 8px;">
                    <source src="static/videos/supernova.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="content has-text-justified">
                  <p>
                    Astrophysical simulation exploration with scientific reasoning. When asked "Tell me what the green part is about," the system identifies it as the shockwave. Follow-up queries like "Show me only the blue part" lead to isolation of turbulent plasma with detailed explanations, demonstrating combined visual reasoning and scientific knowledge.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End case studies section -->


<!-- Pipeline section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">System Pipeline</h2>
          <div class="content has-text-justified">
            <p>
              NLI4VolVis employs a multi-stage pipeline that seamlessly integrates natural language processing with volume visualization. The system consists of four main components:
            </p>
            <div class="columns">
              <div class="column">

                <p><strong>1. Semantic Understanding:</strong> Multi-view semantic segmentation and vision-language models extract and understand semantic components within volumetric scenes, enabling open-vocabulary object querying.</p>
                <p><strong>2. Editable 3D Gaussian Rendering:</strong> The VolVis engine powered by editable 3D Gaussians provides real-time scene editing, best-view selection, and 2D stylization capabilities.</p>
              </div>
              <div class="column">
                <p><strong>3. LLM Multi-Agent Collaboration:</strong> A coordinated system of specialized language model agents interprets user requests, leveraging function-calling tools to decompose complex tasks into executable visualization commands.</p>
                <p><strong>4. Natural Language Interface:</strong> Users input natural language queries through an intuitive chat interface, allowing them to express complex visualization intents without technical expertise.</p>
              </div>
            </div>
          </div>
          <div class="has-text-centered" style="margin-top: 2rem;">
            <img src="static/images/pipeline.jpg" alt="NLI4VolVis Pipeline" style="width: 100%; max-width: 1400px; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
            <p class="subtitle is-6" style="margin-top: 1rem; color: #666;">
              System pipeline overview showing the integration of natural language processing, multi-agent coordination, semantic understanding, and 3D Gaussian-based volume rendering.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End pipeline section -->


<!-- Interface section -->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">Interactive Interface</h2>
          <div class="content has-text-justified">
            <p>
              NLI4VolVis features an intuitive interface that democratizes volume visualization through natural language interaction. The interface seamlessly combines traditional visualization controls with conversational AI, allowing users to express their visualization intents in plain English rather than learning complex technical parameters.
            </p>
          </div>
          <div class="has-text-centered" style="margin-top: 2rem;">
            <img src="static/images/interface.jpg" alt="NLI4VolVis Interface" style="width: 100%; max-width: 1400px; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
            <p class="subtitle is-6" style="margin-top: 1rem; color: #666;">
              The NLI4VolVis interface consists of four key components: (a) panel, (b) rendering window, (c) chat widget, and (d) action log.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End interface section -->


<!-- User Study section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">User Study</h2>
          <div class="content has-text-justified">
            <p>
              We conducted a comprehensive user study to evaluate the effectiveness and usability of NLI4VolVis. The study involved 8 participants with varying levels of visualization expertise, from novices to domain experts, to assess the system's accessibility and practical utility.
            </p>
            
            <h3 class="title is-4">Key Advantages</h3>
            <p>
              The user study revealed several significant advantages of our natural language approach:
            </p>
            <ul>
              <li><strong>Improved Accessibility:</strong> Novice users demonstrated significantly faster task completion times and reduced learning curves when using natural language commands.</li>
              <li><strong>Reduced Cognitive Load:</strong> Users no longer needed to memorize complex parameter relationships or technical visualization terminology, allowing them to focus on data analysis rather than interface mechanics.</li>
              <li><strong>Increased Exploration Efficiency:</strong> The multi-agent system enabled users to perform complex visualization tasks through simple conversational exchanges, leading to more comprehensive data exploration.</li>
            </ul>

            <h3 class="title is-4">Identified Shortcomings</h3>
            <p>
              Despite the overall positive reception, the study also identified areas for improvement:
            </p>
            <ul>
              <li><strong>Ambiguity in Natural Language:</strong> Some participants experienced difficulties when their natural language queries were ambiguous or imprecise, requiring multiple iterations to achieve desired results.</li>
              <li><strong>LLM Latency:</strong> Response delays from the language model agents occasionally disrupted the interactive flow, particularly for complex multi-step visualization tasks.</li>
              <li><strong>Limited Domain Coverage:</strong> The system's effectiveness was constrained by the predefined function tools, occasionally struggling with highly specialized domain-specific terminology.</li>
            </ul>
          </div>
          
          <div class="has-text-centered" style="margin-top: 2rem;">
            <img src="static/images/survey_responses.png" alt="User Study Survey Responses" style="width: 100%; max-width: 1200px; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);"/>
            <p class="subtitle is-6" style="margin-top: 1rem; color: #666;">
            Survey responses to nine post-questionnaire questions, along with mean scores (on a 1–5 scale) and standard deviations.
            </p>
          </div>
          
          <div class="content has-text-justified" style="margin-top: 2rem;">
            <p>
              Overall, the user study demonstrates that NLI4VolVis successfully democratizes volume visualization by making it more accessible to non-expert users while maintaining the sophistication required for complex data exploration tasks. The identified shortcomings provide valuable directions for future improvements, particularly in handling natural language ambiguity and LLM response latency.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End user study section -->

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">System Demonstration</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{ai2025nli4volvis,
  title={NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting},
  author={Ai, Kuangshi and Tang, Kaiyuan and Wang, Chaoli},
  booktitle={Proceedings of IEEE Visualization Conference},
  year={2025},
  organization={IEEE}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
           This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
